üöÄ Updated Implementation Plan with Firebase Structure
Perfect! Now I have the critical information needed. Let me create a comprehensive implementation plan that accounts for the Firebase structure and your infrastructure setup.
üìã Updated Architecture Overview
Data Storage Responsibilities

Firebase: Studio profiles, API keys, feature flags, tier/subscription
BrightMatter: Everything else (game data, events, campaigns, progress, rewards)

Authentication Flow
mermaidGame Client ‚Üí API Key ‚Üí BoredGamer ‚Üí Validate in Firebase ‚Üí Forward to BrightMatter
                                         ‚Üì
                                    Studio ID extracted
                                         ‚Üì
                                    All events tagged with Studio ID
üîß Implementation Plan for AI
1. Redpanda Topic Creation Script
javascript// brightmatter/scripts/create-topics.js
const { Kafka } = require('kafkajs');

const kafka = new Kafka({
  clientId: 'topic-creator',
  brokers: process.env.REDPANDA_BROKERS.split(','),
  sasl: {
    mechanism: 'scram-sha-256',
    username: process.env.REDPANDA_USERNAME,
    password: process.env.REDPANDA_PASSWORD
  },
  ssl: true
});

const topics = [
  {
    topic: 'game.events',
    numPartitions: 10,
    replicationFactor: 3,
    configEntries: [
      { name: 'retention.ms', value: '604800000' }, // 7 days
      { name: 'compression.type', value: 'snappy' }
    ]
  },
  {
    topic: 'config.quests',
    numPartitions: 3,
    replicationFactor: 3
  },
  {
    topic: 'config.leaderboards',
    numPartitions: 3,
    replicationFactor: 3
  },
  {
    topic: 'config.tournaments',
    numPartitions: 3,
    replicationFactor: 3
  },
  {
    topic: 'config.battlepasses',
    numPartitions: 3,
    replicationFactor: 3
  },
  {
    topic: 'quest.events',
    numPartitions: 5,
    replicationFactor: 3
  },
  {
    topic: 'leaderboard.events',
    numPartitions: 5,
    replicationFactor: 3
  },
  {
    topic: 'tournament.events',
    numPartitions: 5,
    replicationFactor: 3
  },
  {
    topic: 'battlepass.events',
    numPartitions: 5,
    replicationFactor: 3
  },
  {
    topic: 'reward.events',
    numPartitions: 5,
    replicationFactor: 3
  },
  {
    topic: 'reward.status',
    numPartitions: 3,
    replicationFactor: 3
  },
  {
    topic: 'ui.updates',
    numPartitions: 10,
    replicationFactor: 3
  }
];

async function createTopics() {
  const admin = kafka.admin();
  
  try {
    await admin.connect();
    
    console.log('Creating topics...');
    await admin.createTopics({
      topics,
      waitForLeaders: true
    });
    
    console.log('Topics created successfully');
    
    // List topics to verify
    const existingTopics = await admin.listTopics();
    console.log('Existing topics:', existingTopics);
    
  } catch (error) {
    console.error('Error creating topics:', error);
  } finally {
    await admin.disconnect();
  }
}

createTopics();
2. API Key Validation Middleware
typescript// boredgamer/src/middleware/api-key-validation.ts
import { db } from '@/lib/firebase-admin';

export async function validateApiKey(apiKey: string) {
  try {
    // Query Firebase for studio with this API key
    const studiosSnapshot = await db
      .collection('studios')
      .where('apiKey', '==', apiKey)
      .limit(1)
      .get();
    
    if (studiosSnapshot.empty) {
      return { valid: false, error: 'Invalid API key' };
    }
    
    const studio = studiosSnapshot.docs[0];
    const studioData = studio.data();
    
    // Check subscription status
    if (studioData.subscriptionStatus !== 'active') {
      return { valid: false, error: 'Subscription inactive' };
    }
    
    return {
      valid: true,
      studioId: studio.id,
      studioData: {
        name: studioData.name,
        tier: studioData.tier,
        features: studioData.features
      }
    };
  } catch (error) {
    console.error('API key validation error:', error);
    return { valid: false, error: 'Validation error' };
  }
}

// Rate limiting configuration
export const rateLimitConfig = {
  ecosystem: { requestsPerMinute: 1000, burstSize: 100 },
  pro: { requestsPerMinute: 5000, burstSize: 500 },
  enterprise: { requestsPerMinute: 20000, burstSize: 2000 }
};
3. BrightMatter Event Ingestion Service
javascript// brightmatter/src/services/event-ingestion.js
const { Kafka } = require('kafkajs');
const { Pool } = require('pg');
const { RateLimiter } = require('./rate-limiter');

class EventIngestionService {
  constructor() {
    this.kafka = new Kafka({
      clientId: 'event-ingestion',
      brokers: process.env.REDPANDA_BROKERS.split(','),
      sasl: {
        mechanism: 'scram-sha-256',
        username: process.env.REDPANDA_USERNAME,
        password: process.env.REDPANDA_PASSWORD
      },
      ssl: true
    });
    
    this.producer = this.kafka.producer();
    this.pool = new Pool({
      connectionString: process.env.RDS_CONNECTION_STRING
    });
    
    this.rateLimiter = new RateLimiter();
  }
  
  async init() {
    await this.producer.connect();
  }
  
  async ingestEvent(event, studioData) {
    // Apply rate limiting based on tier
    const limited = await this.rateLimiter.checkLimit(
      studioData.studioId,
      studioData.tier
    );
    
    if (limited) {
      throw new Error('Rate limit exceeded');
    }
    
    // Validate event schema
    this.validateEvent(event);
    
    // Enrich event with studio data
    const enrichedEvent = {
      ...event,
      studioId: studioData.studioId,
      studioTier: studioData.tier,
      eventId: this.generateEventId(),
      ingestedAt: new Date().toISOString(),
      partitionKey: `${event.gameId}:${event.userId}`
    };
    
    // Send to Kafka
    await this.producer.send({
      topic: 'game.events',
      messages: [{
        key: enrichedEvent.partitionKey,
        value: JSON.stringify(enrichedEvent),
        headers: {
          studioId: studioData.studioId,
          gameId: event.gameId,
          eventType: event.eventType
        }
      }]
    });
    
    // Store raw event for debugging
    await this.storeRawEvent(enrichedEvent);
    
    return {
      eventId: enrichedEvent.eventId,
      status: 'accepted',
      timestamp: enrichedEvent.ingestedAt
    };
  }
  
  validateEvent(event) {
    const required = ['eventType', 'userId', 'gameId', 'timestamp'];
    for (const field of required) {
      if (!event[field]) {
        throw new Error(`Missing required field: ${field}`);
      }
    }
    
    // Validate event type
    const validEventTypes = [
      'match_start', 'match_end', 'score_update',
      'level_complete', 'item_collected', 'enemy_killed',
      'quest_action', 'achievement_unlocked', 'custom'
    ];
    
    if (!validEventTypes.includes(event.eventType)) {
      throw new Error(`Invalid event type: ${event.eventType}`);
    }
  }
  
  generateEventId() {
    return `evt_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }
  
  async storeRawEvent(event) {
    const query = `
      INSERT INTO events_raw (
        event_id, studio_id, game_id, user_id, 
        event_type, event_data, ingested_at
      ) VALUES ($1, $2, $3, $4, $5, $6, $7)
    `;
    
    await this.pool.query(query, [
      event.eventId,
      event.studioId,
      event.gameId,
      event.userId,
      event.eventType,
      JSON.stringify(event.metadata || {}),
      event.ingestedAt
    ]);
  }
}

module.exports = EventIngestionService;
4. Updated Database Schema for BrightMatter
sql-- brightmatter/migrations/001_initial_schema.sql

-- Raw events table (for debugging and replay)
CREATE TABLE events_raw (
  event_id VARCHAR(50) PRIMARY KEY,
  studio_id VARCHAR(50) NOT NULL,
  game_id VARCHAR(100) NOT NULL,
  user_id VARCHAR(255) NOT NULL,
  event_type VARCHAR(50) NOT NULL,
  event_data JSONB NOT NULL,
  ingested_at TIMESTAMPTZ NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Indexes for events_raw
CREATE INDEX idx_events_raw_studio_game ON events_raw(studio_id, game_id);
CREATE INDEX idx_events_raw_user ON events_raw(user_id);
CREATE INDEX idx_events_raw_ingested ON events_raw(ingested_at DESC);

-- Games table (linked to Firebase studios)
CREATE TABLE games (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  studio_id VARCHAR(50) NOT NULL, -- Firebase UID
  game_id VARCHAR(100) UNIQUE NOT NULL,
  name VARCHAR(255) NOT NULL,
  webhook_url TEXT,
  webhook_secret TEXT,
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Quests table
CREATE TABLE quests (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  studio_id VARCHAR(50) NOT NULL,
  game_id VARCHAR(100) NOT NULL,
  quest_id VARCHAR(100) NOT NULL,
  name VARCHAR(255) NOT NULL,
  description TEXT,
  conditions JSONB NOT NULL,
  rewards JSONB,
  start_date TIMESTAMPTZ,
  end_date TIMESTAMPTZ,
  community_gate JSONB,
  status VARCHAR(20) DEFAULT 'active',
  created_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(game_id, quest_id)
);

-- Quest progress
CREATE TABLE quest_progress (
  id BIGSERIAL PRIMARY KEY,
  quest_id UUID REFERENCES quests(id),
  user_id VARCHAR(255) NOT NULL,
  progress JSONB NOT NULL DEFAULT '{}',
  completed BOOLEAN DEFAULT false,
  completed_at TIMESTAMPTZ,
  rewards_claimed BOOLEAN DEFAULT false,
  last_updated TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(quest_id, user_id)
);

-- Leaderboards
CREATE TABLE leaderboards (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  studio_id VARCHAR(50) NOT NULL,
  game_id VARCHAR(100) NOT NULL,
  leaderboard_id VARCHAR(100) NOT NULL,
  name VARCHAR(255) NOT NULL,
  scoring_type VARCHAR(50) NOT NULL, -- 'highest', 'cumulative', 'latest'
  reset_period VARCHAR(20), -- 'daily', 'weekly', 'monthly', 'never'
  formula JSONB,
  community_gate JSONB,
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(game_id, leaderboard_id)
);

-- Leaderboard entries
CREATE TABLE leaderboard_entries (
  id BIGSERIAL PRIMARY KEY,
  leaderboard_id UUID REFERENCES leaderboards(id),
  user_id VARCHAR(255) NOT NULL,
  score NUMERIC NOT NULL DEFAULT 0,
  rank INTEGER,
  metadata JSONB DEFAULT '{}',
  last_updated TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(leaderboard_id, user_id)
);

-- Add indexes
CREATE INDEX idx_leaderboard_entries_score ON leaderboard_entries(leaderboard_id, score DESC);
CREATE INDEX idx_quest_progress_user ON quest_progress(user_id);
5. ECS Task Definition for Processors
json// brightmatter/ecs/task-definitions/quest-processor.json
{
  "family": "brightmatter-quest-processor",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "512",
  "memory": "1024",
  "containerDefinitions": [
    {
      "name": "quest-processor",
      "image": "${ECR_REGISTRY}/brightmatter-processors:latest",
      "command": ["node", "src/processors/quest-processor.js"],
      "environment": [
        {
          "name": "PROCESSOR_TYPE",
          "value": "quest"
        },
        {
          "name": "CONSUMER_GROUP",
          "value": "quest-processor-group"
        }
      ],
      "secrets": [
        {
          "name": "REDPANDA_BROKERS",
          "valueFrom": "arn:aws:secretsmanager:region:account:secret:brightmatter/redpanda-brokers"
        },
        {
          "name": "RDS_CONNECTION_STRING",
          "valueFrom": "arn:aws:secretsmanager:region:account:secret:brightmatter/rds-connection"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/brightmatter",
          "awslogs-region": "${AWS_REGION}",
          "awslogs-stream-prefix": "quest-processor"
        }
      }
    }
  ]
}
6. BoredGamer API Route Updates
typescript// boredgamer/src/app/api/events/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { validateApiKey } from '@/middleware/api-key-validation';
import { BrightMatterClient } from '@/lib/brightmatter-client';

export async function POST(request: NextRequest) {
  try {
    // Extract API key
    const apiKey = request.headers.get('x-api-key');
    if (!apiKey) {
      return NextResponse.json(
        { error: 'Missing API key' },
        { status: 401 }
      );
    }
    
    // Validate API key against Firebase
    const validation = await validateApiKey(apiKey);
    if (!validation.valid) {
      return NextResponse.json(
        { error: validation.error },
        { status: 401 }
      );
    }
    
    // Parse event
    const event = await request.json();
    
    // Forward to BrightMatter
    const brightMatter = new BrightMatterClient();
    const result = await brightMatter.ingestEvent(event, {
      studioId: validation.studioId,
      tier: validation.studioData.tier
    });
    
    return NextResponse.json(result);
    
  } catch (error) {
    console.error('Event ingestion error:', error);
    return NextResponse.json(
      { error: error.message },
      { status: 500 }
    );
  }
}
7. Quest Processor Implementation
javascript// brightmatter/src/processors/quest-processor.js
const { Kafka } = require('kafkajs');
const { Pool } = require('pg');

class QuestProcessor {
  constructor() {
    this.kafka = new Kafka({
      clientId: 'quest-processor',
      brokers: process.env.REDPANDA_BROKERS.split(',')
    });
    
    this.consumer = this.kafka.consumer({ 
      groupId: 'quest-processor-group' 
    });
    
    this.producer = this.kafka.producer();
    
    this.db = new Pool({
      connectionString: process.env.RDS_CONNECTION_STRING
    });
  }
  
  async start() {
    await this.consumer.connect();
    await this.producer.connect();
    
    await this.consumer.subscribe({ 
      topic: 'quest.events', 
      fromBeginning: false 
    });
    
    await this.consumer.run({
      eachMessage: async ({ message }) => {
        await this.processEvent(JSON.parse(message.value.toString()));
      }
    });
  }
  
  async processEvent(event) {
    console.log('Processing quest event:', event.eventId);
    
    try {
      // Get active quests for this game/user
      const quests = await this.getActiveQuests(
        event.gameId, 
        event.userId
      );
      
      for (const quest of quests) {
        if (this.eventMatchesQuest(event, quest)) {
          await this.updateQuestProgress(quest, event);
        }
      }
      
    } catch (error) {
      console.error('Quest processing error:', error);
      // Send to dead letter queue
      await this.sendToDeadLetter(event, error);
    }
  }
  
  async getActiveQuests(gameId, userId) {
    const query = `
      SELECT q.*, qp.progress, qp.completed
      FROM quests q
      LEFT JOIN quest_progress qp ON q.id = qp.quest_id AND qp.user_id = $2
      WHERE q.game_id = $1
        AND q.status = 'active'
        AND (q.start_date IS NULL OR q.start_date <= NOW())
        AND (q.end_date IS NULL OR q.end_date > NOW())
        AND (qp.completed IS NULL OR qp.completed = false)
    `;
    
    const result = await this.db.query(query, [gameId, userId]);
    return result.rows;
  }
  
  eventMatchesQuest(event, quest) {
    const conditions = quest.conditions;
    
    // Check event type matches
    if (conditions.eventType && conditions.eventType !== event.eventType) {
      return false;
    }
    
    // Check additional conditions
    if (conditions.filters) {
      for (const [key, value] of Object.entries(conditions.filters)) {
        if (event.metadata?.[key] !== value) {
          return false;
        }
      }
    }
    
    return true;
  }
  
  async updateQuestProgress(quest, event) {
    const currentProgress = quest.progress || {};
    const updatedProgress = this.calculateProgress(
      quest, 
      currentProgress, 
      event
    );
    
    // Update in database
    const query = `
      INSERT INTO quest_progress (quest_id, user_id, progress, completed, completed_at)
      VALUES ($1, $2, $3, $4, $5)
      ON CONFLICT (quest_id, user_id)
      DO UPDATE SET 
        progress = $3,
        completed = $4,
        completed_at = $5,
        last_updated = NOW()
    `;
    
    const isComplete = this.isQuestComplete(quest, updatedProgress);
    
    await this.db.query(query, [
      quest.id,
      event.userId,
      JSON.stringify(updatedProgress),
      isComplete,
      isComplete ? new Date() : null
    ]);
    
    // If completed, trigger rewards
    if (isComplete && !quest.completed) {
      await this.triggerRewards(quest, event.userId);
    }
    
    // Send UI update
    await this.sendUIUpdate({
      type: 'quest_progress',
      questId: quest.id,
      userId: event.userId,
      progress: updatedProgress,
      completed: isComplete
    });
  }
  
  calculateProgress(quest, currentProgress, event) {
    const progressType = quest.conditions.progressType;
    
    switch (progressType) {
      case 'count':
        return {
          current: (currentProgress.current || 0) + 1,
          target: quest.conditions.target
        };
        
      case 'accumulate':
        const value = event.metadata?.[quest.conditions.valueField] || 1;
        return {
          current: (currentProgress.current || 0) + value,
          target: quest.conditions.target
        };
        
      case 'unique':
        const items = new Set(currentProgress.items || []);
        const itemId = event.metadata?.[quest.conditions.uniqueField];
        if (itemId) items.add(itemId);
        return {
          items: Array.from(items),
          current: items.size,
          target: quest.conditions.target
        };
        
      default:
        return currentProgress;
    }
  }
  
  isQuestComplete(quest, progress) {
    return progress.current >= progress.target;
  }
  
  async triggerRewards(quest, userId) {
    if (!quest.rewards || quest.rewards.length === 0) return;
    
    for (const reward of quest.rewards) {
      await this.producer.send({
        topic: 'reward.events',
        messages: [{
          key: userId,
          value: JSON.stringify({
            userId,
            gameId: quest.game_id,
            source: `quest_${quest.quest_id}`,
            reward,
            timestamp: new Date().toISOString()
          })
        }]
      });
    }
  }
  
  async sendUIUpdate(update) {
    await this.producer.send({
      topic: 'ui.updates',
      messages: [{
        key: update.userId,
        value: JSON.stringify(update)
      }]
    });
  }
}

// Start the processor
const processor = new QuestProcessor();
processor.start().catch(console.error);
üìù Complete AI Implementation Instructions
markdown# BrightMatter Implementation Guide for AI

## Environment Setup
1. Clone the repository
2. Copy .env.example to .env and fill in the values
3. Run `npm install` in both boredgamer/ and brightmatter/ directories

## Implementation Order

### Phase 1: Infrastructure (Day 1)
1. Run the topic creation script
2. Test database connections
3. Deploy base Docker images to ECR

### Phase 2: Event Ingestion (Day 2)
1. Implement event ingestion service
2. Add API key validation to BoredGamer
3. Test end-to-end event flow

### Phase 3: Processors (Days 3-5)
1. Quest processor (start with this - simplest)
2. Leaderboard processor
3. Tournament processor
4. Battle pass processor
5. Reward processor

### Phase 4: Integration (Days 6-7)
1. Update all BoredGamer API routes
2. Add WebSocket support
3. Test with SDK

### Testing Strategy
- Unit tests for each processor
- Integration tests for event flow
- Load test with 1000 events/second
- Manual testing with BoredGamer UI

## Key Implementation Notes

1. **Partition Strategy**: Always use `gameId:userId` as partition key
2. **Idempotency**: Store eventId in Redis with 1-hour TTL
3. **Error Handling**: All errors go to dead letter topic
4. **Monitoring**: Log every event with correlation ID
5. **Rate Limiting**: Implement sliding window per studio

## Deployment Checklist
- [ ] All topics created in Redpanda
- [ ] Database migrations run
- [ ] ECS task definitions created
- [ ] CloudWatch log groups created
- [ ] Secrets Manager secrets configured
- [ ] API Gateway routes configured
- [ ] Load balancer health checks passing
This implementation plan is now ready for AI coding. The key clarifications:

Firebase stores: Studio data, API keys, tier/features
BrightMatter stores: Everything else (game data, progress, etc.)
Authentication: API keys validated against Firebase
Rate limiting: Based on studio tier
Topics: Need to be created (script provided)
Deployment: You'll add ECS tasks manually